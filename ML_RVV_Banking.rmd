---
title: "ML algorithm for Harvardx Capstone Course, Choose Your Own project"
author: "Rubén Vázquez del Valle"
date: "2/10/2021"
output:
  html_document:
    df_print: kable
    fig_caption: true
    toc: true
    latex_engine: xelatex

---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)
```



# 1.Introduction


According to wikipedia:


    1. Marketing is currently defined by the American Marketing Association (AMA) as " the performance of business activities that direct the flow of goods, and services from producers to consumers"
    2. Direct marketing is a form of communicating an offer, where organizations communicate directly to a pre-selected customer and supply a method for a direct response.



Hence we can understand that direct marketing campaigns are several processes producers undertake to engage directly its target consumers, build strong relationships to create value in order to capture value in return and get a fast and direct response.

As time goes by and technology advances those processes evolved, and keep on evolving, from different analog channels such as reply cards, reply forms to be sent in an envelope, to new and more sophisticated digital ones such as  websites, text messages sent to cellular phone and/or email addresses.

One not so long old-fashioned direct marketing technique was phone calls.

The purpose of this project is analyzing if such technique applied in this case by a Portuguese banking institution not so much time ago, had positive effect or not in its clients, or in other words building a classification system to predict if the client would subscribe a term deposit.

The origin dataset has been downloaded from The UCI Machine Learning Repository: 
https://archive.ics.uci.edu/ml/machine-learning-databases/00222/


Once dataset was created, I have based my work on *"HarvardX - PH125.8x course: Data Science - Machine Learning"* specifically on machine learning techniques applied to supervised learning.



```{r loading-libs, message=FALSE}

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(rvest)) install.packages("rvest", repos = "http://cran.us.r-project.org")
if(!require(httr)) install.packages("httr", repos = "http://cran.us.r-project.org")
if(!require(genefilter)) install.packages("genefilter", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(rvest)
library(httr)
library(genefilter)

```


```{r loading-functions, message=FALSE}
###############################################################################
###############################################################################
##        Functions specifically created for the project
###############################################################################
###############################################################################

## substrRight function to substract n last characters on a string
substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}


## substrLeft function to substract n first characters on a string
substrLeft <- function(x, n){
  substr(x, 1, n)
}


```

\newpage  

# 2 Methodology

Next step consist on analyzing the data provided, cleaning, wrangling and preparing it in case of actions were needed to decide which kind of algorithms will be worthy in terms of classification problems.


## 2.1 Exploratory Analysis


```{r Downloading-data, message=FALSE}

################################################################################################################
# Download source data set, and split it between training, test and validation sets (final hold-out test set)
################################################################################################################

# Note: this process could take a couple of minutes


# URL with original dataset to be downloaded
url<-"https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#"
url2<-"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/"
  
  
file<-"bank-additional.zip"

dfile<-paste(url2,file,sep="")


# Create input folder on working directory to download source files
mydir<-getwd()
inputdir<-paste(mydir,"/Input",sep="")
dir.create(path=inputdir,mode="0777")

# Download source files, unzip them and erase temp files
dl <- tempfile()
download.file(dfile,dl)
untar(dl,exdir=inputdir)
rm(dl)


#Looking for downloading directory
dirs<-list.dirs()
idx_dirs<-grep(paste("/Input",substrLeft(file,15),sep="/"),dirs)
dw_dir<-dirs[idx_dirs]

#List files tp download
dw_files<-list.files(path=dw_dir)

#Download n all files and save them into Input_file_n  tibbles
for(i in (1:length(dw_files))){
exp1 <- expression(paste("Input_file",as.character(i),sep="_"))                                  # Create name of the tibble expression
exp2<- expression(read_delim(file=paste(dw_dir,dw_files[i],sep="/"),delim=";",col_names=TRUE))   # Create read_delim expression
z<-paste(eval(exp1),exp2,sep="<-")                                                               # Create assignation expression as a string
eval(parse(text=z))                                                                              # Evaluate expression
}

```

After downloading source data it is observable that there are three files compressed: `r format(dw_files,big.mark=",")`


`r format(dw_files[2],big.mark=",")` is a text document with some basic information about the remaining ones. Here it is stated that `r format(dw_files[3],big.mark=",")` is a random sample subset of `r format(dw_files[1],big.mark=",")` 

Applying basic relational algebra, a simple way to confirm that a set B is a subset of another one A, is getting the cardinality of B/A, or equivalently getting the size of the anti_join function. While anti_join() return all rows from B without a match in A, having and antijoin by all columns with size 0  means that all rows in B are present in A, which indeed confirms that B is a subset of A.

Hence applying anti_join to  `r format(dw_files[3],big.mark=",")` on `r format(dw_files[1],big.mark=",")` by all columns, the number of rows obtained is: `r format(nrow(anti_join(Input_file_3,Input_file_1,by=NULL)),big.mark=",",scientific=F)` which confirms that data file to be used is `r format(dw_files[1],big.mark=",")`


Now that source data has been properly addressed, let's continue by exploring and summarizing the dataset `r format(dw_files[1],big.mark=",")`:


```{r Exploratory Analysis, message=FALSE}

head(Input_file_1[1:10])
head(Input_file_1[11:21])
summary(Input_file_1)


#Build an index with all character columns in the dataset that will need to become factor
idx_isc<-which(sapply(Input_file_1,is.character)==TRUE)

```

At simple glance, it can be observed that the dataset is a data.frame containing `r format(nrow(Input_file_1),big.mark=",",scientific=F)` rows and `r format(ncol(Input_file_1),big.mark=",",scientific=F)` columns, the last one with the prediction values. It is also evident the split between numerical data and categorical data. In order to be able to address this first issue it is necessary to transform characters into factors for columns: `r format(colnames(Input_file_1[idx_isc]),big.mark=",",scientific=F)` 

Let's explore possible values for the categorical columns 


```{r Exploratory Analysis 2, message=FALSE}
# Get values for character columns
for(i in (1:length(idx_isc))){
  #The idea is building for each character column the sentence that will cast it to a factor column. For instance:
  # Input_file_1$job<-factor(Input_file_1$job)
  # Instead of building one by one and taking advantage of having them stored in idx_isc, I will build the expression.
  exp1 <- expression(paste("Input_file_1",colnames(Input_file_1[idx_isc])[i],sep="$"))       # Input_file_1$**** expression
  exp2<-expression(factor(eval(parse(text=eval(exp1)))))                                     # factor(Input_file_1$****) expression
  exp3<-expression(levels(factor(eval(parse(text=eval(exp1))))))                             # levels(factor(Input_file_1$****)) expression
  cat(colnames(Input_file_1[idx_isc])[i],"possible values are :",eval(exp3),"\n")
  z<-paste(eval(exp1),exp2,sep="<-")                                                         # Create a<-factor(a) expression 
  eval(parse(text=z))    
}  

```



Once categorical values have been transformed from character to factor, let's look again how the values of those columns are distributed
```{r Exploratory Analysis 3, message=FALSE}
summary(Input_file_1[idx_isc])


```


At this point, it is fair to assume then that description of columns of our dataset provided in file `r format(dw_files[2],big.mark=",")` is correct, stating the following:

    1.  age: Age of the client.
    2.  job: Type of job of the client.
    3.  marital: Marital status, note "divorced" means divorced or widowed.
    4.  education: Educational degree reached by the client. 
    5.  default: Binary variable meaning if the client has credit/credits in default.
    6.  housing: Binary variable meaning if the client has a mortgage.
    7.  loan: Binary variable meaning if the client has a personal loan.
    8.  contact: Contact communication type with the client.
    9.  month: Last contact month of year.
    10. day_of_week: Last contact day of the week.
    11. duration: Last contact duration, in seconds. 
    12. campaign: For each  client, number of contacts performed during this campaign. 
    13. pdays: Number of days since last contact from a previous campaign (999 means client was not previously contacted).
    14. previous: For each  client, number of contacts performed before this campaign.
    15. poutcome: Outcome of the previous marketing campaign if existing.
    16. emp.var.rate: Employment variation rate - quarterly indicator.
    17. cons.price.idx: Consumer price index - monthly indicator.
    18. cons.conf.idx: Consumer confidence index - monthly indicator.
    19. euribor3m: Euribor 3 month rate - daily indicator.
    20. nr.employed: Number of employees - quarterly indicator.
    21. y: Output binary variable if the client has subscribed a term deposit or not. 
    
    


## 2.2.Transforming and partitioning original dataset

Apart from previous transformations in original dataset related to categorical variables transformed into factor variables, there is also a implicit transformation needed. The ouput variable y, needs to be numeric so let's map it to 1 if the value is yes and to 0 in case no term deposit were subscribed.

```{r Transforming, message=FALSE}
Input_file_1$y<-ifelse(as.numeric(Input_file_1$y)==2,1,0)

```



## 2.3 Modelling


### 2.3.1 BASELINE PREDICTORS


\newpage

# 3.Results


\newpage

# 4.Conclusions


\newpage

# 5.Bibliography
